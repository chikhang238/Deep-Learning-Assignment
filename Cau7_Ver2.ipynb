{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Improved_Cau7.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6iCFxI01USyN","colab_type":"code","colab":{}},"source":["import warnings \n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgKakGVJUl9f","colab_type":"code","outputId":"3cf0c83c-187c-44dc-a304-7ee76077ace5","executionInfo":{"status":"ok","timestamp":1572949955815,"user_tz":-420,"elapsed":3226,"user":{"displayName":"Khang Nguyễn Ngô Chí","photoUrl":"","userId":"18181510532343489000"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["from keras.layers import Input\n","from keras.models import Model, Sequential\n","from keras.layers.core import Reshape, Dense, Dropout, Flatten\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import Convolution2D, UpSampling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.optimizers import Adam\n","from keras import backend as K\n","from keras import initializers\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"gFPZmtp-dq5D","colab_type":"code","outputId":"ef223dce-007c-44c6-e4b1-02fba2dcb945","executionInfo":{"status":"ok","timestamp":1572950004133,"user_tz":-420,"elapsed":51532,"user":{"displayName":"Khang Nguyễn Ngô Chí","photoUrl":"","userId":"18181510532343489000"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["from google.colab  import drive\n","drive.mount('/content/gdrive', force_remount = True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lxUbqbsYdxK5","colab_type":"code","colab":{}},"source":["path = '/content/gdrive/My Drive/THI'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RPrtN9LcVZfy","colab_type":"code","colab":{}},"source":["def get_optimizer():\n","  return Adam(lr = 0.0002, beta_1=0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5IgtqBqVkS4","colab_type":"code","colab":{}},"source":["def get_generator(optimizer):\n","  generator = Sequential()\n","  generator.add(Dense(1152, input_dim = 100, kernel_initializer = initializers.RandomNormal(stddev=0.02)))\n","  generator.add(LeakyReLU(0.2))\n","\n","\n","  generator.add(Dense(2304))\n","  generator.add(LeakyReLU(0.2))\n","\n","  \n","  generator.add(Dense(4608))\n","  generator.add(LeakyReLU(0.2))\n","\n"," \n","  generator.add(Dense(2304, activation = 'tanh'))\n","  generator.compile(loss = 'binary_crossentropy', optimizer = optimizer)\n","  return generator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjzCgCQDg9co","colab_type":"code","colab":{}},"source":["def get_discriminator(optimizer):\n","  discriminator = Sequential()\n","  discriminator.add(Dense(4608, input_dim = 2304, kernel_initializer= initializers.RandomNormal(stddev=0.02)))\n","  discriminator.add(LeakyReLU(0.2))    \n","  discriminator.add(Dropout(0.3))\n"," \n","  discriminator.add(Dense(2304))    \n","  discriminator.add(LeakyReLU(0.2))    \n","  discriminator.add(Dropout(0.3))\n"," \n","  discriminator.add(Dense(1152))    \n","  discriminator.add(LeakyReLU(0.2))    \n","  discriminator.add(Dropout(0.3))\n","\n","  discriminator.add(Dense(1, activation='sigmoid'))\n","  discriminator.compile(loss = 'binary_crossentropy', optimizer=optimizer)\n","  return discriminator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_4ZnUC9j75G","colab_type":"code","colab":{}},"source":["def get_GAN_network(discriminator, random_dim, generator, optimizer):\n","  discriminator.trainable = False \n","  \n","  gan_input = Input(shape=(random_dim,))  \n","\n","  x = generator(gan_input)      \n","  \n","  gan_output = discriminator(x)    \n","  \n","  gan = Model(inputs=gan_input, outputs=gan_output)    \n","  \n","  gan.compile(loss='binary_crossentropy', optimizer=optimizer)    \n","  \n","  return gan"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4JSRVMzKo42I","colab_type":"code","colab":{}},"source":["def plot_generated_images(epoch, generator, examples = 100, dim = (10,10), figsize = (10,10)):\n","  noise = np.random.normal(0,1,size = [examples, 100])\n","\n","  generated_images = generator.predict(noise)    \n","  generated_images = generated_images.reshape((examples, 48, 48))\n","  plt.figure(figsize=figsize)    \n","  for i in range(generated_images.shape[0]):        \n","    plt.subplot(dim[0], dim[1], i+1)        \n","    plt.imshow(generated_images[i], interpolation='nearest')        \n","    plt.axis('off')    \n","  plt.tight_layout()\n","  plt.savefig(path+'/GAN_1/gan_generated_image_epoch_%d.png' % epoch)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5BTWf6EMd3o1","colab_type":"code","outputId":"2a3edc97-ef1b-41ae-b5dd-0ac77afc9dbb","executionInfo":{"status":"ok","timestamp":1572950012996,"user_tz":-420,"elapsed":60366,"user":{"displayName":"Khang Nguyễn Ngô Chí","photoUrl":"","userId":"18181510532343489000"}},"colab":{"base_uri":"https://localhost:8080/","height":194}},"source":["import pandas as pd\n","emotion = pd.read_csv(path + '/emotion.csv')\n","emotion.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>emotion</th>\n","      <th>pixels</th>\n","      <th>Usage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n","      <td>Training</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   emotion                                             pixels     Usage\n","0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n","1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n","2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n","3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n","4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"CFtd68kkelUm","colab_type":"code","colab":{}},"source":["import numpy as np\n","def reshape_string_listofnumber(df, index):\n","  string = df[index]\n","  string = string.split(' ')\n","  lst = np.array([int(charac) for charac in string])\n","\n","  return lst\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1WvoPC3EYrk7","colab_type":"code","colab":{}},"source":["def reshape_dataset_matrix(df):\n","  matrix = np.empty((df.shape[0], 48, 48, 1))\n","  for i in range(df.shape[0]):\n","    ele = reshape_string_listofnumber(df, i)\n","    ele = np.reshape(ele,(48,48,1))\n","    matrix[i] = ele\n","\n","  return matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qlxwfh_vexjU","colab_type":"code","colab":{}},"source":["def train(epochs = 1, batch_size = 128):\n","  x_train = emotion.pixels[emotion.Usage == 'Training']\n","  x_test = emotion.pixels[emotion.Usage == 'PrivateTest'].reset_index(drop = True)\n","\n","  x_train = reshape_dataset_matrix(x_train)\n","  x_test = reshape_dataset_matrix(x_test)\n","\n","  x_train = (x_train.astype(np.float32) - 127.5)/127.5\n","  x_test = (x_test.astype(np.float32) - 127.5)/127.5\n","\n","  x_train = np.reshape(x_train, (x_train.shape[0], 2304))\n","  x_test = np.reshape(x_test, (x_test.shape[0], 2304))\n","\n","  batch_count = x_train.shape[0]/batch_size\n","\n","  adam = get_optimizer()\n","  generator = get_generator(adam)\n","  discriminator = get_discriminator(adam)\n","  gan = get_GAN_network(discriminator, 100, generator, adam)\n","\n","  for e in range(1, epochs+1):\n","    print('-'*10, 'Epoch %d' %e, '-'*10)\n","    for _ in tqdm(range(int(batch_count))):\n","      noise = np.random.normal(0, 1, size = [batch_size, 100])\n","      image_batch = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n","\n","      generated_images = generator.predict(noise)\n","\n","      X = np.concatenate([image_batch, generated_images])\n","      y_dis = np.zeros(2*batch_size)\n","      y_dis[:batch_size] = 0.9\n","\n","      discriminator.trainable = True\n","      discriminator.train_on_batch(X, y_dis)\n","\n","      noise = np.random.normal(0, 1, size = [batch_size, 100])\n","      y_gen = np.ones(batch_size)\n","      discriminator.trainable = False\n","      gan.train_on_batch(noise, y_gen)\n","\n","    if e == 1 or e%20 == 0:\n","      plot_generated_images(e, generator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XdEiFB0tYz-j","colab_type":"code","colab":{}},"source":["train(400,128)"],"execution_count":0,"outputs":[]}]}